{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_dreivative_1(f,x):\n",
    "    delta_x = 1e-4\n",
    "    return (f(x+delta_x)-f(x-delta_x))/(2*delta_x)\n",
    "\n",
    "def numerical_derivate(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val)+delta_x\n",
    "        fx1 = f(x)\n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1-fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val;\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "t_data = np.array([2,3,4,5,6]).reshape(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50847347]] [0.48438474]\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "print(W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x,W) + b # np.dot 행렬곱\n",
    "    return np.sum((t-y)**2/len(x))\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x, W) + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial err =  4.444072208276979 W = [[0.50847347]] b =  [0.48438474]\n",
      "step =  0 err =  2.624722186431999 W = [[0.64754622]] b =  [0.51584428]\n",
      "step =  400 err =  0.0017210086375269741 W = [[1.02693942]] b =  [0.90276395]\n",
      "step =  800 err =  0.00010981052563052502 W = [[1.00680485]] b =  [0.97543834]\n",
      "step =  1200 err =  7.006560732070478e-06 W = [[1.00171889]] b =  [0.99379576]\n",
      "step =  1600 err =  4.4705999730264595e-07 W = [[1.00043419]] b =  [0.99843282]\n",
      "step =  2000 err =  2.852507083448855e-08 W = [[1.00010968]] b =  [0.99960413]\n",
      "step =  2400 err =  1.820068158683131e-09 W = [[1.0000277]] b =  [0.9999]\n",
      "step =  2800 err =  1.1613110872805369e-10 W = [[1.000007]] b =  [0.99997474]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "print(\"initial err = \",loss_func(x_data, t_data), \"W =\", W,\"b = \",b)\n",
    "for step in range(3001):\n",
    "    W -= learning_rate * numerical_derivate(f, W)\n",
    "    b -= learning_rate * numerical_derivate(f, b)\n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \",step,\"err = \",loss_func(x_data, t_data), \"W =\", W,\"b = \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.loadtxt('./sps.csv',delimiter=',',dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9be12f73b2b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mt_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_data' is not defined"
     ]
    }
   ],
   "source": [
    "x_data = loaded_data[:,1:]\n",
    "t_data = loaded_data[:,[0]]\n",
    "W = np.random.rand(4,1)\n",
    "b = np.random.rand(1)\n",
    "def loss_func(x, t):\n",
    "    y = np.dot(x,W) + b # np.dot 행렬곱\n",
    "    return (np.sum((t-y)**2/len(x)))\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x, W) + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial err =  2.933452312496878e-11 W = [[1.00000352]] b =  [0.99998731]\n",
      "step =  0 err =  2.913340088143678e-11 W = [[1.00000351]] b =  [0.99998735]\n",
      "step =  400 err =  1.8588832129768156e-12 W = [[1.00000089]] b =  [0.9999968]\n",
      "step =  800 err =  1.1860773871592008e-13 W = [[1.00000022]] b =  [0.99999919]\n",
      "step =  1200 err =  7.567874936313824e-15 W = [[1.00000006]] b =  [0.9999998]\n",
      "step =  1600 err =  4.828751751920014e-16 W = [[1.00000001]] b =  [0.99999995]\n",
      "step =  2000 err =  3.081029142204901e-17 W = [[1.]] b =  [0.99999999]\n",
      "step =  2400 err =  1.9658794110483826e-18 W = [[1.]] b =  [1.]\n",
      "step =  2800 err =  1.2543488178421134e-19 W = [[1.]] b =  [1.]\n",
      "step =  3200 err =  8.00349425151999e-21 W = [[1.]] b =  [1.]\n",
      "step =  3600 err =  5.106628279085355e-22 W = [[1.]] b =  [1.]\n",
      "step =  4000 err =  3.258654656500995e-23 W = [[1.]] b =  [1.]\n",
      "step =  4400 err =  2.0806919899892957e-24 W = [[1.]] b =  [1.]\n",
      "step =  4800 err =  1.3300243179756703e-25 W = [[1.]] b =  [1.]\n",
      "step =  5200 err =  8.666662563029601e-27 W = [[1.]] b =  [1.]\n",
      "step =  5600 err =  5.713325106063178e-28 W = [[1.]] b =  [1.]\n",
      "step =  6000 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  6400 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  6800 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  7200 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  7600 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  8000 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  8400 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  8800 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  9200 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  9600 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  10000 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  10400 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  10800 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  11200 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  11600 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  12000 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  12400 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  12800 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  13200 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  13600 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  14000 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  14400 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  14800 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  15200 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  15600 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  16000 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  16400 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  16800 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  17200 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  17600 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  18000 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  18400 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  18800 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  19200 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  19600 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n",
      "step =  20000 err =  9.517606821491507e-29 W = [[1.]] b =  [1.]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "print(\"initial err = \",loss_func(x_data, t_data), \"W =\", W,\"b = \",b)\n",
    "for step in range(20001):\n",
    "    W -= learning_rate * numerical_derivate(f, W)\n",
    "    b -= learning_rate * numerical_derivate(f, b)\n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \",step,\"err = \",loss_func(x_data, t_data), \"W =\", W,\"b = \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.array([1,2,3,4]).reshape(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n"
     ]
    }
   ],
   "source": [
    "print(int(predict(test_set)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
